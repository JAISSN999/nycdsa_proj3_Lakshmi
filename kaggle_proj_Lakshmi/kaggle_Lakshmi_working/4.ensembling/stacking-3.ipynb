{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, HashingVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "#submission_1 = pd.read_csv(\"F:/kaggle_Lakshmi_worked/submission.csv\")    #only tes data\n",
    "#submission_2 = pd.read_csv(\"F:/one_more_blend.csv\")                 #only tet data\n",
    "submission_3 = pd.read_csv(\"superblend_1.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312735, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_text = pd.read_csv('kaggle_proj_Lakshmi/kaggle_Lakshmi_working/3.important words/imptext.csv')\n",
    "imp_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "train = pd.read_csv('kaggle_proj_Lakshmi/train.csv').fillna('No data')\n",
    "test = pd.read_csv('kaggle_proj_Lakshmi/test.csv').fillna('No data')\n",
    "\n",
    "#train.id = train.id.astype('str')\n",
    "#train.comment_text = train.comment_text.astype('str')\n",
    "\n",
    "#test.id = test.id.astype('str')\n",
    "#test.comment_text = test.comment_text.astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_3['comment_text'] = test.comment_text\n",
    "submission_3.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = submission_3.copy()\n",
    "new = new[['id', 'comment_text']]\n",
    "new['toxic'] = [1 if x >=0.4 else 0 for x in submission_3.toxic]\n",
    "new['severe_toxic'] = [1 if x >=0.4 else 0 for x in submission_3.severe_toxic]\n",
    "new['obscene'] = [1 if x >=0.4 else 0 for x in submission_3.obscene]\n",
    "new['threat'] = [1 if x >=0.4 else 0 for x in submission_3.threat]\n",
    "new['insult'] = [1 if x >=0.4 else 0 for x in submission_3.insult]\n",
    "new['identity_hate'] = [1 if x >=0.4 else 0 for x in submission_3.identity_hate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_3.to_csv('super1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312735, 8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked = pd.concat([train, new])\n",
    "stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train[['id', 'comment_text']]\n",
    "test_text = test[['id', 'comment_text']]\n",
    "combined_text = stacked[['id', 'comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 2)\n",
      "(153164, 2)\n",
      "id                                               fff46fc426af1f9a\n",
      "comment_text    \"\\nAnd ... I really don't think you understand...\n",
      "Name: 159570, dtype: object\n",
      "id                                               00001cee341fdb12\n",
      "comment_text    Yo bitch Ja Rule is more succesful then you'll...\n",
      "Name: 0, dtype: object\n",
      "id                                               fff46fc426af1f9a\n",
      "comment_text    \"\\nAnd ... I really don't think you understand...\n",
      "Name: 159570, dtype: object\n",
      "id                                               00001cee341fdb12\n",
      "comment_text    Yo bitch Ja Rule is more succesful then you'll...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print train_text.shape\n",
    "print test_text.shape\n",
    "print train_text.iloc[train_text.shape[0]-1, ]\n",
    "print test_text.iloc[0, ]\n",
    "print combined_text.iloc[train_text.shape[0]-1,]\n",
    "print combined_text.iloc[train_text.shape[0],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = imp_text.loc[imp_text.comment.isna(), ]\n",
    "missing_index = list(missing.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont use errors='ignore'\n",
    "combined_text.comment_text = map(lambda x:unicode(x, 'utf-8'), combined_text.comment_text)\n",
    "#combined_text = map(lambda x:unicode(x, 'utf-8'), combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the stopwords from nltk library\n",
    "sw = stopwords.words('english')\n",
    "# displaying the stopwords\n",
    "np.array(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords(text):\n",
    "    '''a function for removing the stopword'''\n",
    "# removing the stop words and lowercasing the selected words\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    # joining the list of words with space separator\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>d'aww! matches background colour i'm seemingly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man, i'm really trying edit war. guy const...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\" can't make real suggestions improvement - wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>you, sir, hero. chance remember page that's on?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\" congratulations well, use tools well. Â· talk \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>cocksucker piss around work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>vandalism matt shirvington article reverted. p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>sorry word 'nonsense' offensive you. anyway, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment subject contrary dulithgow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  0000997932d777bf  explanation edits made username hardcore metal...\n",
       "1  000103f0d9cfb60f  d'aww! matches background colour i'm seemingly...\n",
       "2  000113f07ec002fd  hey man, i'm really trying edit war. guy const...\n",
       "3  0001b41b1c6bb37e  \" can't make real suggestions improvement - wo...\n",
       "4  0001d958c54c6e35    you, sir, hero. chance remember page that's on?\n",
       "5  00025465d4725e87   \" congratulations well, use tools well. Â· talk \"\n",
       "6  0002bcb3da6cb337                        cocksucker piss around work\n",
       "7  00031b1e95af7921  vandalism matt shirvington article reverted. p...\n",
       "8  00037261f536c51d  sorry word 'nonsense' offensive you. anyway, i...\n",
       "9  00040093b2687caa               alignment subject contrary dulithgow"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_text['comment_text'] = combined_text['comment_text'].apply(stopwords)\n",
    "combined_text.head(10)\n",
    "#combined_text = map(stopwords, combined_text)\n",
    "#combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>daww matches background colour im seemingly st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man im really trying edit war guy constant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>cant make real suggestions improvement - wond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>you sir hero chance remember page thats on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>congratulations well use tools well Â· talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>cocksucker piss around work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>vandalism matt shirvington article reverted pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>sorry word nonsense offensive you anyway im in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment subject contrary dulithgow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  0000997932d777bf  explanation edits made username hardcore metal...\n",
       "1  000103f0d9cfb60f  daww matches background colour im seemingly st...\n",
       "2  000113f07ec002fd  hey man im really trying edit war guy constant...\n",
       "3  0001b41b1c6bb37e   cant make real suggestions improvement - wond...\n",
       "4  0001d958c54c6e35         you sir hero chance remember page thats on\n",
       "5  00025465d4725e87        congratulations well use tools well Â· talk \n",
       "6  0002bcb3da6cb337                        cocksucker piss around work\n",
       "7  00031b1e95af7921  vandalism matt shirvington article reverted pl...\n",
       "8  00037261f536c51d  sorry word nonsense offensive you anyway im in...\n",
       "9  00040093b2687caa               alignment subject contrary dulithgow"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PunctuationToRemove = [\".\", \",\", \":\", \";\", \"!\" ,\"?\", \"&\", \"\\\"\", \"\\'\", \"~\",  \"=\", \"@\", \"$\", \"[\", \"]\", \"(\", \")\", \"/\", \"{\", \"}\", \"|\", \">\",\"<\",  \"\\\\\", \"+\", \"%\", \"#\"]\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    '''a function for removing punctuation'''\n",
    "    for char in PunctuationToRemove:\n",
    "        text = text.replace(char,\"\")\n",
    "    return text\n",
    "combined_text['comment_text'] = combined_text['comment_text'].apply(remove_punctuation)\n",
    "combined_text.head(10)\n",
    "#combined_text = map(remove_punctuation, combined_text)\n",
    "#combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = list(combined_text.iloc[missing_index, 1])\n",
    "#missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_text1 = imp_text.copy()\n",
    "imp_text1.iloc[missing_index, 0] = missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imp_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = imp_text1.comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 25265 tokens in Comment_text if we use word\n"
     ]
    }
   ],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    encoding='utf-8',\n",
    "    lowercase=True,\n",
    "    #min_df=0.00001,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    #use_idf=1, smooth_idf=1,\n",
    "    max_features=None)\n",
    "\n",
    "word_vectorizer.fit(all_text)\n",
    "train_word_features = word_vectorizer.transform(stacked.comment_text)\n",
    "test_word_features = word_vectorizer.transform(test_text.comment_text)\n",
    "\n",
    "msg = \"There are {} tokens in Comment_text if we use word\"\n",
    "print(msg.format(len(word_vectorizer.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.986669734525\n",
      "CV score for class severe_toxic is 0.991601882637\n",
      "CV score for class obscene is 0.993873254319\n",
      "CV score for class threat is 0.988791573613\n",
      "CV score for class insult is 0.98646178656\n",
      "CV score for class identity_hate is 0.988434403464\n",
      "Total CV score is 0.989305439186\n"
     ]
    }
   ],
   "source": [
    "#train_features = hstack([train_char_features, train_word_features])\n",
    "#test_features = hstack([test_char_features, test_word_features])\n",
    "#X_train, X_valid, y_train, y_valid = train_test_split(train_features, train_target, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "scores = []\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "for class_name in class_names:\n",
    "    train_target = stacked[class_name]\n",
    "    classifier = LogisticRegression(solver='sag')\n",
    "\n",
    "    cv_score = np.mean(cross_val_score(classifier, train_word_features, train_target, cv=3, scoring='roc_auc'))\n",
    "    scores.append(cv_score)\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "\n",
    "    classifier.fit(train_word_features, train_target)\n",
    "    submission[class_name] = classifier.predict_proba(test_word_features)[:, 1]\n",
    "\n",
    "print('Total CV score is {}'.format(np.mean(scores)))\n",
    "\n",
    "submission.to_csv('mysubmission3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.981240128886\n",
      "CV score for class severe_toxic is 0.987429907895\n",
      "CV score for class obscene is 0.990806882068\n",
      "CV score for class threat is 0.983957897517\n",
      "CV score for class insult is 0.981914569155\n",
      "CV score for class identity_hate is 0.981067329785\n",
      "Total CV score is 0.984402785884\n"
     ]
    }
   ],
   "source": [
    "#train_features = hstack([train_char_features, train_word_features])\n",
    "#test_features = hstack([test_char_features, test_word_features])\n",
    "\n",
    "scores = []\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "for class_name in class_names:\n",
    "    train_target = stacked[class_name]\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(train_word_features, train_target, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "    classifier = LogisticRegression(solver='sag')\n",
    "\n",
    "    cv_score = np.mean(cross_val_score(classifier, X_valid, y_valid, cv=3, scoring='roc_auc'))\n",
    "    scores.append(cv_score)\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    #submission[class_name] = classifier.predict_proba(test_word_features)[:, 1]\n",
    "\n",
    "print('Total CV score is {}'.format(np.mean(scores)))\n",
    "\n",
    "#submission.to_csv('F:\\impwordssub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.946554920876\n",
      "CV score for class severe_toxic is 0.936215919315\n",
      "CV score for class obscene is 0.9355287361\n",
      "CV score for class threat is 0.886947003746\n",
      "CV score for class insult is 0.93722629103\n",
      "CV score for class identity_hate is 0.914459874538\n",
      "Total CV score is 0.926155457601\n"
     ]
    }
   ],
   "source": [
    "#train_features = hstack([train_char_features, train_word_features])\n",
    "#test_features = hstack([test_char_features, test_word_features])\n",
    "\n",
    "scores = []\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "for class_name in class_names:\n",
    "    train_target = stacked[class_name]\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(train_word_features, train_target, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "    classifier = MultinomialNB()\n",
    "\n",
    "    cv_score = np.mean(cross_val_score(classifier, X_valid, y_valid, cv=3, scoring='roc_auc'))\n",
    "    scores.append(cv_score)\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    #submission[class_name] = classifier.predict_proba(test_word_features)[:, 1]\n",
    "\n",
    "print('Total CV score is {}'.format(np.mean(scores)))\n",
    "\n",
    "#submission.to_csv('F:\\impwordssub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
