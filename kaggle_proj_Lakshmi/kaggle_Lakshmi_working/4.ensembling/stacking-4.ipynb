{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, HashingVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "submission_3 = pd.read_csv(\"superblend_1.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "train = pd.read_csv('kaggle_proj_Lakshmi/train.csv').fillna('No data')\n",
    "test = pd.read_csv('kaggle_proj_Lakshmi/test.csv').fillna('No data')\n",
    "\n",
    "#train.id = train.id.astype('str')\n",
    "#train.comment_text = train.comment_text.astype('str')\n",
    "\n",
    "#test.id = test.id.astype('str')\n",
    "#test.comment_text = test.comment_text.astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_3['comment_text'] = test.comment_text\n",
    "submission_3.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = submission_3.copy()\n",
    "new = new[['id', 'comment_text']]\n",
    "new['toxic'] = [1 if x >= 0.5 else 0 for x in submission_3.toxic]\n",
    "new['severe_toxic'] = [1 if x >= 0.5 else 0 for x in submission_3.severe_toxic]\n",
    "new['obscene'] = [1 if x >= 0.5 else 0 for x in submission_3.obscene]\n",
    "new['threat'] = [1 if x >= 0.5 else 0 for x in submission_3.threat]\n",
    "new['insult'] = [1 if x >= 0.5 else 0 for x in submission_3.insult]\n",
    "new['identity_hate'] = [1 if x >= 0.5 else 0 for x in submission_3.identity_hate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312735, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked = pd.concat([train, new])\n",
    "stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train[['id', 'comment_text']]\n",
    "test_text = test[['id', 'comment_text']]\n",
    "combined_text = stacked[['id', 'comment_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imp_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 62311 tokens in Comment_text if we use word\n"
     ]
    }
   ],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    encoding='utf-8',\n",
    "    lowercase=True,\n",
    "    min_df=0.00001,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    #use_idf=1, smooth_idf=1,\n",
    "    max_features=None)\n",
    "\n",
    "word_vectorizer.fit(combined_text.comment_text)\n",
    "train_word_features = word_vectorizer.transform(stacked.comment_text)\n",
    "test_word_features = word_vectorizer.transform(test_text.comment_text)\n",
    "\n",
    "msg = \"There are {} tokens in Comment_text if we use word\"\n",
    "print(msg.format(len(word_vectorizer.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.97719047262\n",
      "CV score for class severe_toxic is 0.990332264938\n",
      "CV score for class obscene is 0.986147514504\n",
      "CV score for class threat is 0.980374583097\n",
      "CV score for class insult is 0.978111173144\n",
      "CV score for class identity_hate is 0.973003191267\n",
      "Total CV score is 0.980859866595\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.990884      0.087384  0.948575  0.008777  0.649078   \n",
      "1  0000247867823ef7  0.003902      0.001251  0.002033  0.000766  0.003216   \n",
      "2  00013b17ad220c46  0.020768      0.001975  0.008696  0.000840  0.010336   \n",
      "3  00017563c3f7919a  0.001701      0.001113  0.001781  0.000586  0.002650   \n",
      "4  00017695ad8997eb  0.020130      0.001018  0.004389  0.001021  0.005544   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.064072  \n",
      "1       0.001654  \n",
      "2       0.002055  \n",
      "3       0.000575  \n",
      "4       0.001254  \n"
     ]
    }
   ],
   "source": [
    "#train_features = hstack([train_char_features, train_word_features])\n",
    "#test_features = hstack([test_char_features, test_word_features])\n",
    "#X_train, X_valid, y_train, y_valid = train_test_split(train_features, train_target, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "scores = []\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "for class_name in class_names:\n",
    "    train_target = stacked[class_name]\n",
    "    classifier = LogisticRegression(solver='sag')\n",
    "\n",
    "    cv_score = np.mean(cross_val_score(classifier, train_word_features, train_target, cv=3, scoring='roc_auc'))\n",
    "    scores.append(cv_score)\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "\n",
    "    classifier.fit(train_word_features, train_target)\n",
    "    submission[class_name] = classifier.predict_proba(test_word_features)[:, 1]\n",
    "\n",
    "print('Total CV score is {}'.format(np.mean(scores)))\n",
    "print submission.head()\n",
    "submission.to_csv('mysubmission4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.980953488273\n",
      "CV score for class severe_toxic is 0.985811848279\n",
      "CV score for class obscene is 0.99076922687\n",
      "CV score for class threat is 0.982669141613\n",
      "CV score for class insult is 0.980363178041\n",
      "CV score for class identity_hate is 0.979922374566\n",
      "Total CV score is 0.983414876274\n"
     ]
    }
   ],
   "source": [
    "#train_features = hstack([train_char_features, train_word_features])\n",
    "#test_features = hstack([test_char_features, test_word_features])\n",
    "\n",
    "scores = []\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "for class_name in class_names:\n",
    "    train_target = stacked[class_name]\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(train_word_features, train_target, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "    classifier = LogisticRegression(solver='sag')\n",
    "\n",
    "    cv_score = np.mean(cross_val_score(classifier, X_valid, y_valid, cv=3, scoring='roc_auc'))\n",
    "    scores.append(cv_score)\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    #submission[class_name] = classifier.predict_proba(test_word_features)[:, 1]\n",
    "\n",
    "print('Total CV score is {}'.format(np.mean(scores)))\n",
    "\n",
    "#submission.to_csv('F:\\impwordssub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.981490249653\n",
      "CV score for class severe_toxic is 0.988404743899\n",
      "CV score for class obscene is 0.990830873049\n",
      "CV score for class threat is 0.985799281\n",
      "CV score for class insult is 0.981899729415\n",
      "CV score for class identity_hate is 0.982936343245\n",
      "Total CV score is 0.985226870044\n"
     ]
    }
   ],
   "source": [
    "#train_features = hstack([train_char_features, train_word_features])\n",
    "#test_features = hstack([test_char_features, test_word_features])\n",
    "\n",
    "scores = []\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "for class_name in class_names:\n",
    "    train_target = stacked[class_name]\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(train_word_features, train_target, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "    classifier = LogisticRegression(solver='sag')\n",
    "\n",
    "    cv_score = np.mean(cross_val_score(classifier, X_valid, y_valid, cv=3, scoring='roc_auc'))\n",
    "    scores.append(cv_score)\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    #submission[class_name] = classifier.predict_proba(test_word_features)[:, 1]\n",
    "\n",
    "print('Total CV score is {}'.format(np.mean(scores)))\n",
    "\n",
    "#submission.to_csv('F:\\impwordssub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.946554920876\n",
      "CV score for class severe_toxic is 0.936215919315\n",
      "CV score for class obscene is 0.9355287361\n",
      "CV score for class threat is 0.886947003746\n",
      "CV score for class insult is 0.93722629103\n",
      "CV score for class identity_hate is 0.914459874538\n",
      "Total CV score is 0.926155457601\n"
     ]
    }
   ],
   "source": [
    "#train_features = hstack([train_char_features, train_word_features])\n",
    "#test_features = hstack([test_char_features, test_word_features])\n",
    "\n",
    "scores = []\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "for class_name in class_names:\n",
    "    train_target = stacked[class_name]\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(train_word_features, train_target, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "    classifier = MultinomialNB()\n",
    "\n",
    "    cv_score = np.mean(cross_val_score(classifier, X_valid, y_valid, cv=3, scoring='roc_auc'))\n",
    "    scores.append(cv_score)\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    #submission[class_name] = classifier.predict_proba(test_word_features)[:, 1]\n",
    "\n",
    "print('Total CV score is {}'.format(np.mean(scores)))\n",
    "\n",
    "#submission.to_csv('F:\\impwordssub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153164"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrow = submission.shape[0]\n",
    "nrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.9135828262516\n",
      "72.8271656525032\n",
      "78.09602778720848\n",
      "76.55388994802956\n",
      "72.5346687211094\n",
      "74.48943615993315\n"
     ]
    }
   ],
   "source": [
    "#0.4 - all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.11201065524536"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0.5 -a ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.05045572066543"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.54255569193805"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.69125904259487"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.0639314721475"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.15154997257841\n",
      "72.82455407275862\n",
      "73.05176151053773\n",
      "75.54190279700191\n",
      "66.69125904259487\n",
      "72.06458436708365\n"
     ]
    }
   ],
   "source": [
    "print (submission.toxic > submission_3.toxic).sum() * 100.0/nrow\n",
    "print (submission.severe_toxic > submission_3.severe_toxic).sum() * 100.0/nrow\n",
    "print (submission.obscene > submission_3.obscene).sum() * 100.0/nrow\n",
    "print (submission.threat > submission_3.threat).sum() * 100.0/nrow\n",
    "print (submission.insult > submission_3.insult).sum() * 100.0/nrow\n",
    "print (submission.identity_hate > submission_3.identity_hate).sum() * 100.0/nrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.980116340304\n",
      "CV score for class severe_toxic is 0.989187863459\n",
      "CV score for class obscene is 0.990446982521\n",
      "CV score for class threat is 0.992291470522\n",
      "CV score for class insult is 0.982473016854\n",
      "CV score for class identity_hate is 0.984439740257\n",
      "Total CV score is 0.986492568986\n",
      "91.24206732652581\n",
      "92.24556684338356\n",
      "96.01407641482332\n",
      "87.47225196521376\n",
      "95.54595074560602\n",
      "90.68645373586483\n",
      "CV score for class toxic is 0.984276468095\n",
      "CV score for class severe_toxic is 0.991735028311\n",
      "CV score for class obscene is 0.99284920974\n",
      "CV score for class threat is 0.991464208727\n",
      "CV score for class insult is 0.98534382777\n",
      "CV score for class identity_hate is 0.988503637282\n",
      "Total CV score is 0.989028729987\n",
      "86.11618918283669\n",
      "82.25758011020866\n",
      "90.77067718262776\n",
      "81.40098195398396\n",
      "88.69381839074457\n",
      "82.97445875009794\n",
      "CV score for class toxic is 0.985867154156\n",
      "CV score for class severe_toxic is 0.992231170471\n",
      "CV score for class obscene is 0.993664754104\n",
      "CV score for class threat is 0.99128746406\n",
      "CV score for class insult is 0.986287426311\n",
      "CV score for class identity_hate is 0.990159334024\n",
      "Total CV score is 0.989916217188\n",
      "80.43730902823118\n",
      "75.81546577524745\n",
      "84.11833067822727\n",
      "78.30299548196705\n",
      "79.83533989710376\n",
      "77.82377059883524\n",
      "CV score for class toxic is 0.986604597417\n",
      "CV score for class severe_toxic is 0.99178972105\n",
      "CV score for class obscene is 0.993740340224\n",
      "CV score for class threat is 0.989947696676\n",
      "CV score for class insult is 0.986303943222\n",
      "CV score for class identity_hate is 0.988827557426\n",
      "Total CV score is 0.989535642669\n",
      "73.91292993131545\n",
      "72.82781854743935\n",
      "78.09537489227233\n",
      "76.55258415815727\n",
      "72.53271003630095\n",
      "74.48943615993315\n",
      "CV score for class toxic is 0.986149290461\n",
      "CV score for class severe_toxic is 0.99033217791\n",
      "CV score for class obscene is 0.993447027231\n",
      "CV score for class threat is 0.987861570082\n",
      "CV score for class insult is 0.986109979656\n",
      "CV score for class identity_hate is 0.986864216135\n",
      "Total CV score is 0.988460710246\n",
      "67.15089707764227\n",
      "71.11201065524536\n",
      "73.05110861560158\n",
      "75.54190279700191\n",
      "66.68995325272257\n",
      "72.0639314721475\n",
      "CV score for class toxic is 0.98530913502\n",
      "CV score for class severe_toxic is 0.988046751197\n",
      "CV score for class obscene is 0.992650628247\n",
      "CV score for class threat is 0.986175579135\n",
      "CV score for class insult is 0.985079085001\n",
      "CV score for class identity_hate is 0.982852201908\n",
      "Total CV score is 0.986685563418\n",
      "60.354260792353294\n",
      "70.40100806978141\n",
      "68.56898487895327\n",
      "74.87137969757906\n",
      "62.85484839779583\n",
      "70.4760909874383\n",
      "CV score for class toxic is 0.984207401915\n",
      "CV score for class severe_toxic is 0.98378792978\n",
      "CV score for class obscene is 0.991471365994\n",
      "CV score for class threat is 0.984062981261\n",
      "CV score for class insult is 0.982637209336\n",
      "CV score for class identity_hate is 0.978612455126\n",
      "Total CV score is 0.984129890569\n",
      "53.9069232979029\n",
      "70.58512444177482\n",
      "64.60591261654174\n",
      "74.40913008278707\n",
      "60.379723694863024\n",
      "69.51372385155781\n",
      "CV score for class toxic is 0.982064270679\n",
      "CV score for class severe_toxic is 0.978626724846\n",
      "CV score for class obscene is 0.989626496856\n",
      "CV score for class threat is 0.980374791818\n",
      "CV score for class insult is 0.978111169438\n",
      "CV score for class identity_hate is 0.973003291614\n",
      "Total CV score is 0.980301124209\n",
      "49.0167402261628\n",
      "71.05194432111985\n",
      "61.533389047034554\n",
      "74.2589642474733\n",
      "59.13334726175864\n",
      "69.10892899114674\n",
      "CV score for class toxic is 0.977190480688\n",
      "CV score for class severe_toxic is 0.975075394688\n",
      "CV score for class obscene is 0.986147565742\n",
      "CV score for class threat is 0.97750074291\n",
      "CV score for class insult is 0.968475592171\n",
      "CV score for class identity_hate is 0.964955343744\n",
      "Total CV score is 0.974890853324\n",
      "45.40100806978141\n",
      "71.52464025489019\n",
      "60.28178945444099\n",
      "74.3647332271291\n",
      "59.279595727455536\n",
      "69.1807474341229\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in a:\n",
    "    new = submission_3.copy()\n",
    "    new = new[['id', 'comment_text']]\n",
    "    new['toxic'] = [1 if x > i else 0 for x in submission_3.toxic]\n",
    "    new['severe_toxic'] = [1 if x > i else 0 for x in submission_3.severe_toxic]\n",
    "    new['obscene'] = [1 if x > i else 0 for x in submission_3.obscene]\n",
    "    new['threat'] = [1 if x > i else 0 for x in submission_3.threat]\n",
    "    new['insult'] = [1 if x > i else 0 for x in submission_3.insult]\n",
    "    new['identity_hate'] = [1 if x > i else 0 for x in submission_3.identity_hate]\n",
    "    stacked = pd.concat([train, new])\n",
    "    scores = []\n",
    "    submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "    for class_name in class_names:\n",
    "        train_target = stacked[class_name]\n",
    "        classifier = LogisticRegression(solver='sag')\n",
    "\n",
    "        cv_score = np.mean(cross_val_score(classifier, train_word_features, train_target, cv=3, scoring='roc_auc'))\n",
    "        scores.append(cv_score)\n",
    "        print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "\n",
    "        classifier.fit(train_word_features, train_target)\n",
    "        submission[class_name] = classifier.predict_proba(test_word_features)[:, 1]\n",
    "\n",
    "    print('Total CV score is {}'.format(np.mean(scores)))\n",
    "    #print submission.head()\n",
    "#submission.to_csv('mysubmission5.csv', index=False)\n",
    "#calcuaitng the differences\n",
    "    print (submission.toxic > submission_3.toxic).sum() * 100.0/nrow\n",
    "    print (submission.severe_toxic > submission_3.severe_toxic).sum() * 100.0/nrow\n",
    "    print (submission.obscene > submission_3.obscene).sum() * 100.0/nrow\n",
    "    print (submission.threat > submission_3.threat).sum() * 100.0/nrow\n",
    "    print (submission.insult > submission_3.insult).sum() * 100.0/nrow\n",
    "    print (submission.identity_hate > submission_3.identity_hate).sum() * 100.0/nrow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
